---
title: "The Data-Intensive Research Workflow"
subtitle: "Orientation Module: Code-Along"
format:
  revealjs: 
    slide-number: c/t
    progress: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: img/LASERLogoB.png
    theme: [default, css/laser.scss]
    width: 1920
    height: 1080
    margin: 0.05
    footer: <a href=https://www.go.ncsu.edu/laser-institute>go.ncsu.edu/laser-institute
resources:
  - demo.pdf
bibliography: lit/references.bib
editor: visual
---

## Overview

![Data-Intensive Research Workflow [@krumm2018]](img/laser-cycle.png){fig-align="center" width="60%"}

::: notes
**Speaker Notes:**

**Slide Overview:** This slide illustrates the data-intensive research workflow, which is a cyclical process and which we use to frame all of the case studies for each module. Each stage is interconnected, emphasizing the iterative nature of the research process. Let’s briefly walk through each stage.

**Prepare:** The preparation phase involves defining and refining the research questions, ensuring they are clear and relevant to the data at hand. This stage sets the foundation for the entire research process, establishing the goals and objectives that guide the subsequent stages.

**Wrangle:** Data wrangling is the process of cleaning, transforming, and merging raw data into a structured format suitable for analysis. This stage is crucial as it ensures the data is accurate, complete, and ready for exploration and modeling.

**Explore:** In the exploration phase, researchers perform exploratory data analysis (EDA) to uncover patterns, trends, and insights within the data. Visualization tools and statistical methods are commonly used to gain a deeper understanding of the dataset, which helps inform the modeling stage.

**Model:** The modeling phase involves building and evaluating predictive models based on the prepared and explored data. Various statistical and machine learning techniques are applied to predict outcomes or classify data, with a focus on accuracy and reliability.

**Communicate:** Effective communication of findings is essential. In this stage, researchers present their results through polished data products, such as reports, visualizations, and presentations, tailored to their intended audience. The goal is to ensure that the insights are clear and actionable.

**Iterative Nature:** The dashed lines in the diagram indicate the iterative nature of this workflow. New analyses often lead to refinements in the research questions or data, prompting a return to the preparation or wrangling stages. Additionally, communicating findings can generate new ideas for further analysis, creating a continuous cycle of improvement and discovery.
:::

## Prepare

::: panel-tabset
### Research Context

-   The setting of this study was a public provider of individual online courses in a Midwestern state.

-   Data was collected from two semesters of five online science courses and aimed to understand students motivation.

### Question

<br>

> Is there a relationship between the time students spend in a learning management system and their final course grade?

### Data

The data used in this case study has already been "wrangled" quite a bit, but the original datasets included:

1.  A self-report **survey** assessing three aspects of students' motivation

2.  **Log-trace data** from the learning management system (LMS) including discussion board posts

3.  **Administrative** **records** including academic achievement and student demographic data

### Packages

Sometimes referred to as "libraries", packages are shareable collections of R code that can contain functions, data, and/or documentation.

```{r, echo=TRUE}
# Load the {tidyverse} package

library(tidyverse)

# How to install the package if not already installed
# install.packages("tidyverse")
# Note this code is commented out so it will not run
```
:::

## Wrangle

::: panel-tabset
## Define

Data wrangling is the process of cleaning, ["tidying"](https://r4ds.had.co.nz/tidy-data.html?q=tidy%20data#tidy-data-1), and transforming data. In Learning Analytics, it often involves merging (or joining) data from multiple sources.

## “Read”

The {readr} tidyverse package has several functions like `read_csv()` for importing rectangular data from delimited text files such as comma-separated values (CSV), a preferred file format for reproducible research.

```{r, echo = TRUE, message = FALSE}
# "read" into your R environment the sci-online-classes.csv file 
# stored in the data folder of your R project and
# save as a new data "object" named sci_data 

sci_data <- read_csv("data/sci-online-classes.csv", 
                     col_names = TRUE)
```

R has also packages for proprietary data formats like .xls, .sas, and .dat.

## Inspect

You should now see a new data "object" named `sci_data` saved in your Environment pane. Try clicking on it and see what happens!

Now let's "print" the output to our Console to view another way:

```{r, echo = TRUE, message = FALSE, results = FALSE}
# print data to console to view

sci_data
```

What variables do you think might help us answer our research question?

## Select

Since we are interested the relationship between time spent in an online course and final grades, let's `select()` the `FinalGradeCEMS` and `TimeSpent` from `sci_data`.

```{r, echo=TRUE, eval = FALSE}
# select student_id and course_id and save as 

sci_data |> 
  select(FinalGradeCEMS, TimeSpent)
```

Note the use of a the powerful `|>` operator called a **pipe**, which are used for combining a sequence of functions or processes.

## Discuss

The R language can express complex ideas like in this simple "sentence":

`sci_data <- read_csv("data/sci-online-classes.csv", col_names = TRUE)`

-   *Functions* are like verbs: `read_csv()`
-   *Objects* are the nouns: `read_csv("data/sci-online-classes.csv")`
-   *Arguments* are like adverbs: `read_csv("data/sci-online-classes.csv", col_names = TRUE)`
-   *Operators* are like “punctuation” `sci_data <- read_csv("data/sci-online-classes.csv", col_names = TRUE)`
:::

## Explore

::: panel-tabset
### EDA

Exploratory data analysis involves processes of **describing** your data numerically or graphically and often involves:

-   **calculating** summary statistics like frequency, means and standard deviations

-   **visualizing** your data through charts and graphs

EDA can be used to help answer research questions or generate new questions about your data, discover relationships between and among variables, and create new variables for data modeling.

### Graph Template

The [{ggplot2}](https://ggplot2.tidyverse.org) package follows a common [graphing workflow](https://r4ds.had.co.nz/data-visualisation.html?q=template#a-graphing-template) for making graphs. To make a graph, you simply:

1.  Start the graph with `ggplot()` function and include your data as an argument;
2.  "Add" elements to the graph using the `+` operator `a geom_()` function;
3.  Select variables to graph on each axis with the `aes()` argument.

A common graphing template is as simple as two lines of code:

```{r, echo=TRUE, eval=FALSE}
ggplot(<DATA>) + 
  <GEOM_FUNCTION>(aes(x = <VARIABLE1>, y = <VARIABLE2>))
```

### Our First Plot!

Scatterplots use the point **geom**, i.e., the `geom_point()` function, and are most useful for displaying the relationship between two continuous variables.

```{r, echo=TRUE, message=FALSE, fig.show='hide', warning=FALSE}
# make a scatter plot showing time spent and final grades
ggplot(sci_data) +
  geom_point(aes(x = TimeSpent, y = FinalGradeCEMS))
```

### Interpret Graph

::: columns
::: {.column width="50%"}
Hopefully your scatterplot looks like something like the one to the right.

<br>

*How would you interpret this graph?*
:::

::: {.column width="50%"}
```{r, echo=FALSE, message=FALSE, fig.width = 7, fig.height = 5.5, warning=FALSE}
ggplot(sci_data) +
  geom_point(aes(x = TimeSpent, y = FinalGradeCEMS))
```
:::
:::
:::

## Model

::: panel-tabset
### Goal

According to @krumm2018, there are two general types of approaches:

-   **Unsupervised** learning algorithms can be used to understand the structure of one’s dataset.

-   **Supervised** models, on the other hand, help to quantify relationships between features and a known outcome.

Ideally, a good model will separate true “signals” (i.e. patterns generated by the phenomenon of interest) from the “noise” (i.e. random variation that you’re not interested in).

### A Simple Model

We'll dive much deeper into modeling in subsequent learning labs, but for now let's see if there is a statistically significant relationship between students' final grades, `FinaGradeCEMS`, and the `TimeSpent` in the LMS:

```{r, echo=TRUE, results = FALSE, message=FALSE, eval=TRUE}
# use a simple linear regression model to predict final course grades
m1 <- lm(FinalGradeCEMS ~ TimeSpent, data = sci_data)

summary(m1)
```

### Interpret

```{r, echo=FALSE, message=FALSE, eval=TRUE}
m1 <- lm(FinalGradeCEMS ~ TimeSpent, data = sci_data)

summary(m1)
```

### Discuss

Our simple model suggests that there is a statistically significant, though relatively small, positive association between the time spent in the LMS and a student's final grade. However, many other factors not included in the model may be influencing final grades.
:::

## Communicate

::: panel-tabset
## Data Products

Krumm et al. (2018) have outlined the following 3-step process for communicating finding with education stakeholders:

1.  **Select.** Selecting analyses that are most important and useful to an intended audience, as well as selecting a format for displaying that info (e.g. chart, table).

2.  **Polish.** Refining or polishing data products, by adding or editing titles, labels, and notations and by working with colors and shapes to highlight key points.

3.  **Narrate.** Writing a narrative pairing a data product with its related research question and describing how best to interpret and use the data product.

## Dashboards

[![](img/data-dashboard.png){fig-align="center" width="60%"}](https://sbkellogg.quarto.pub/final-grades-and-hours-logged/)

## Websites

[![](img/laser-website.png){fig-align="center" width="60%"}](https://laser-institute.github.io/laser-website/)

## Books

[![](img/books.png){fig-align="center" width="60%"}](https://datascienceineducation.com)

## And More!

```{=html}
<iframe width="2000" height="800" src="https://quarto.org/docs/guide/" title="Webpage example"></iframe>
```
:::

## What's Next

Next you will complete an interactive "case study" which is a key component to each LASER Module.

<br>

Navigate to the Files tab and open the following file:

`orientation-case-study-R.qmd`

## Acknowledgements

::: columns
::: {.column width="20%"}
![](img/nsf.jpg){fig-align="center" width="80%"}
:::

::: {.column width="80%"}
This work was supported by the National Science Foundation grants DRL-2025090 and DRL-2321128 (ECR:BCSER). Any opinions, findings, and conclusions expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.
:::
:::

## References
